env:
  grid_dims: 32x32
  n_starts: 3
  n_goals: 3
  n_bridges: 20
  n_episode_steps: 25
  action_success_rate: 0.65
  utility_scale: 2
  terminal_reward: 30
  bridge_cost_lb: 2
  bridge_cost_ub: 10
  duplicate_bridge_penalty: 250

agent:
  n_episodes: 250
  n_training_steps: 20000
  n_episodes_testing: 25
  n_warmup_episodes: 25

  dqn:
    alpha: 0.001
    dropout: 0.2
    epsilon: 0.3
    gamma: 0.99
    batch_size: 4
    hidden_dims: 128
    n_hidden_layers: 1
    buffer_size: 5000
    target_update_freq: 10
