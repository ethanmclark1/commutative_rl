env:
  n_steps: 100
  step_scale: 0.05
  over_penalty: 10
  under_penalty: 0.1
  complete_reward: 100
  n_statistics: 2

agent:
  num_episodes: 500
  n_timesteps: 10000
  num_episodes_testing: 100

  qtable:
    alpha: 0.05
    gamma: 0.99
    epsilon: 0.25

  dqn:
    alpha: 0.0001
    gamma: 0.99
    epsilon: 0.25
    batch_size: 512
    hidden_dims: 64
    buffer_size: 250000
    target_update_freq: 1000

    loss_fn: 'MSE'
    layer_norm: True
    grad_clip_norm: 1
