env:
  n_steps: 100
  step_scale: 1
  over_penalty: 100
  under_penalty: 1
  completion_reward: 0
  max_noise: 10

agent:
  num_episodes: 1000
  n_training_steps: 10000
  num_episodes_testing: 100

  qtable:
    alpha: 0.1
    gamma: 0.99
    epsilon: 0.25

  dqn:
    alpha: 0.0003
    gamma: 0.99
    epsilon: 0.25
    batch_size: 64
    learning_start_step: 512
    hidden_dims: 32
    n_hidden_layers: 1
    buffer_size: 100000
    target_update_freq: 150
    loss_fn: 'Huber'
    activation_fn: 'ReLU'
    layer_norm: True
    grad_clip_norm: 1
