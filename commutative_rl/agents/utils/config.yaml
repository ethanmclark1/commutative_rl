env:
  grid_dims: 12x12
  n_starts: 3
  n_goals: 3
  n_bridges: 12
  n_episode_steps: 300
  action_success_rate: 0.75
  utility_scale: 25
  terminal_reward: 200
  duplicate_bridge_penalty: 500
  bridge_stages: 2

agent:
  n_episodes: 500
  n_training_steps: 10000
  n_episodes_testing: 10
  n_warmup_episodes: 25

  q_table:
    alpha: 0.01
    epsilon: 0.25
    gamma: 0.99
