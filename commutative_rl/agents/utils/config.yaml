env:
  n_episode_steps: 15
  granularity: 0.25
  terminal_reward: 1
  duplicate_line_penalty: 10
  safe_area_multiplier: 2
  failed_path_penalty: 1
  configs_to_consider: 50

agent:
  n_episodes: 200
  n_training_steps: 10000
  n_episodes_testing: 3
  n_warmup_episodes: 100

  dqn:
    alpha: 0.0005
    dropout: 0.2
    gamma: 0.99
    epsilon: 0.25
    batch_size: 4
    hidden_dims: 128
    n_hidden_layers: 1
    buffer_size: 5000
    target_update_freq: 10
