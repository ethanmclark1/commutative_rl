env:
  grid_dims: 12x12
  n_starts: 3
  n_goals: 3
  n_bridges: 12
  n_episode_steps: 300
  action_success_rate: 0.65
  utility_scale: 30
  terminal_reward: 25
  early_termination_penalty: 10
  duplicate_bridge_penalty: 300
  bridge_stages: 2
  bridge_cost_lb: 0
  bridge_cost_ub: 1

agent:
  n_episodes: 2000
  n_training_steps: 2500
  n_episodes_testing: 10

  qtable:
    alpha: 0.01
    epsilon: 0.25
    gamma: 0.99

  dqn:
    alpha: 0.001
    dropout: 0.2
    gamma: 0.99
    epsilon: 0.25
    batch_size: 4
    hidden_dims: 128
    n_hidden_layers: 1
    buffer_size: 5000
    target_update_freq: 10
