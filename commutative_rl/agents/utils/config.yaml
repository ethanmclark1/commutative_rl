env:
  grid_dims: 32x32
  n_starts: 3
  n_goals: 3
  n_bridges: 20
  n_episode_steps: 25
  action_success_rate: 0.75
  utility_scale: 25
  terminal_reward: 100
  bridge_cost_lb: 0
  bridge_cost_ub: 0.5
  duplicate_bridge_penalty: 20

agent:
  n_episodes: 250
  n_training_steps: 20000
  n_episodes_testing: 10
  n_warmup_episodes: 25

  dqn:
    alpha: 0.001
    dropout: 0.2
    epsilon: 0.3
    gamma: 0.99
    batch_size: 4
    hidden_dims: 128
    n_hidden_layers: 1
    buffer_size: 5000
    target_update_freq: 10
